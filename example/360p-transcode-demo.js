/**
 * 360pè§†é¢‘è½¬ç ç¤ºä¾‹ - æ¼”ç¤ºå®Œæ•´çš„æ‰‹åŠ¨ç¼–è§£ç æµç¨‹
 * 
 * åŠŸèƒ½ï¼š
 * 1. è§†é¢‘ç¼©æ”¾åˆ°æœ€å¤§è¾¹360pï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
 * 2. MOOVåŸå­å‰ç½®ï¼ˆfaststartï¼Œä¼˜åŒ–æµåª’ä½“æ’­æ”¾ï¼‰
 * 3. ç ç‡è°ƒæ•´ï¼ˆè§†é¢‘å’ŒéŸ³é¢‘ï¼‰
 * 4. å®Œå…¨æ‰‹åŠ¨çš„è§£ç ->å¤„ç†->ç¼–ç æµç¨‹
 * 5. éŸ³é¢‘å¸§ç¼“å†²é‡ç»„ï¼ˆå¤„ç†AACç¼–ç å™¨çš„å›ºå®šå¸§å¤§å°è¦æ±‚ï¼‰
 */

const path = require('path');
const { MidLevel } = require('../dist/index.js');

const {
  // ä¸Šä¸‹æ–‡ç®¡ç†
  openInput,
  createOutput,
  getInputStreams,
  addOutputStream,
  closeContext,

  // ç¼–è§£ç å™¨
  createEncoder,
  createDecoder,
  setEncoderOption,
  openEncoder,
  copyDecoderParams,
  openDecoder,

  // è¾“å‡ºé€‰é¡¹
  setOutputOption,
  writeHeader,
  writeTrailer,
  copyEncoderToStream,

  // å¸§å’ŒåŒ…æ“ä½œ
  allocFrame,
  allocPacket,
  freeFrame,
  freePacket,
  readPacket,
  writePacket,
  sendPacket,
  receiveFrame,
  sendFrame,
  receivePacket,

  // å¸§æ•°æ®æ“ä½œ
  frameGetBuffer,
  getFrameProperty,
  setFrameProperty,
  getFrameData,
  setFrameData,

  // è§†é¢‘ç¼©æ”¾
  createSwsContext,
  swsScale,

  // åŒ…å±æ€§
  getPacketProperty,

  // AudioFIFO API - ä¸“ä¸šéŸ³é¢‘ç¼“å†²ç®¡ç†
  audioFifoAlloc,
  audioFifoFree,
  audioFifoWrite,
  audioFifoRead,
  audioFifoSize,
  audioFifoSpace,
  audioFifoReset,
} = MidLevel;

/**
 * éŸ³é¢‘å¸§ç¼“å†²å™¨ - ä½¿ç”¨FFmpeg AudioFIFOå®ç°ä¸“ä¸šçº§éŸ³é¢‘ç¼“å†²é‡ç»„
 * ç”¨äºæ»¡è¶³AACç¼–ç å™¨çš„å›ºå®šå¸§å¤§å°è¦æ±‚ï¼ˆ1024é‡‡æ ·/å¸§ï¼‰
 * 
 * âœ¨ æ–°ç‰ˆæœ¬ç‰¹æ€§ï¼š
 * - ä½¿ç”¨åŸç”ŸFFmpeg AudioFIFO APIï¼ˆé«˜æ€§èƒ½Cå®ç°ï¼‰
 * - è‡ªåŠ¨å¤„ç†åŠ¨æ€å¤§å°æ‰©å±•
 * - é›¶æ‹·è´æ•°æ®ä¼ è¾“ï¼ˆFrame -> FIFO -> Frameï¼‰
 * - å®Œç¾å¤„ç†ä¸è§„åˆ™é‡‡æ ·æ•°çš„éŸ³é¢‘å¸§
 */
class AudioFrameBuffer {
  constructor(targetSamples, channels, sampleFormat) {
    this.targetSamples = targetSamples; // ç›®æ ‡é‡‡æ ·æ•° (AAC = 1024)
    this.channels = channels;
    this.sampleFormat = sampleFormat; // 8 = AV_SAMPLE_FMT_FLTP
    
    // åˆ›å»ºAudioFIFOï¼ˆåˆå§‹å®¹é‡ä¸ºç›®æ ‡é‡‡æ ·æ•°çš„2å€ï¼‰
    this.fifoId = audioFifoAlloc(sampleFormat, channels, targetSamples * 2);
    
    // ä¿å­˜ç¬¬ä¸€å¸§çš„æ ¼å¼ä¿¡æ¯
    this.firstFrameFormat = null;
    
    console.log(`âœ“ AudioFIFOå·²åˆ›å»º (format=${sampleFormat}, channels=${channels}, capacity=${targetSamples * 2})`);
  }

  /**
   * æ·»åŠ éŸ³é¢‘å¸§åˆ°FIFOç¼“å†²åŒº
   * @param {number} frameId - è§£ç åçš„éŸ³é¢‘å¸§ID
   */
  addFrame(frameId) {
    // ç¬¬ä¸€æ¬¡æ·»åŠ å¸§æ—¶ï¼Œä¿å­˜æ ¼å¼ä¿¡æ¯
    if (!this.firstFrameFormat) {
      this.firstFrameFormat = {
        format: getFrameProperty(frameId, 'format'),
        sampleRate: getFrameProperty(frameId, 'sample_rate'),
      };
    }
    
    // ç›´æ¥å†™å…¥FIFOï¼ˆé›¶æ‹·è´ï¼‰
    const samplesWritten = audioFifoWrite(this.fifoId, frameId);
    
    return samplesWritten;
  }

  /**
   * æ£€æŸ¥FIFOæ˜¯å¦æœ‰è¶³å¤Ÿçš„é‡‡æ ·è¾“å‡ºå®Œæ•´å¸§
   */
  hasEnoughSamples() {
    return audioFifoSize(this.fifoId) >= this.targetSamples;
  }

  /**
   * ä»FIFOæå–ä¸€ä¸ªå®Œæ•´çš„ç›®æ ‡å¤§å°å¸§
   * @param {number} outputFrameId - é¢„åˆ†é…çš„è¾“å‡ºå¸§ID
   * @returns {boolean} æ˜¯å¦æˆåŠŸæå–
   */
  extractFrame(outputFrameId) {
    if (!this.hasEnoughSamples() || !this.firstFrameFormat) {
      return false;
    }

    // è®¾ç½®è¾“å‡ºå¸§çš„å±æ€§ï¼ˆå¿…é¡»åœ¨frameGetBufferä¹‹å‰ï¼‰
    setFrameProperty(outputFrameId, 'format', this.firstFrameFormat.format);
    setFrameProperty(outputFrameId, 'sample_rate', this.firstFrameFormat.sampleRate);
    setFrameProperty(outputFrameId, 'channels', this.channels); // âœ¨ ä½¿ç”¨æ–°çš„channelså±æ€§
    setFrameProperty(outputFrameId, 'nb_samples', this.targetSamples);
    
    // åˆ†é…å¸§ç¼“å†²åŒºï¼ˆç°åœ¨channelså·²è®¾ç½®ï¼Œä¸ä¼šå¤±è´¥ï¼‰
    frameGetBuffer(outputFrameId, 0);

    // ä»FIFOè¯»å–æ•°æ®åˆ°è¾“å‡ºå¸§ï¼ˆé›¶æ‹·è´ï¼‰
    const samplesRead = audioFifoRead(this.fifoId, outputFrameId, this.targetSamples);
    
    return samplesRead === this.targetSamples;
  }

  /**
   * è·å–FIFOä¸­å½“å‰çš„é‡‡æ ·æ•°
   */
  get totalSamples() {
    return audioFifoSize(this.fifoId);
  }

  /**
   * æ¸…ç©ºFIFOç¼“å†²åŒº
   */
  clear() {
    audioFifoReset(this.fifoId);
  }

  /**
   * é‡Šæ”¾FIFOèµ„æº
   */
  destroy() {
    if (this.fifoId !== null) {
      audioFifoFree(this.fifoId);
      this.fifoId = null;
      console.log('âœ“ AudioFIFOå·²é‡Šæ”¾');
    }
  }
}

/**
 * è®¡ç®—ç¼©æ”¾åçš„å°ºå¯¸ï¼ˆæœ€å¤§è¾¹360pï¼Œä¿æŒå®½é«˜æ¯”ï¼‰
 */
function calculate360pSize(width, height) {
  const maxDim = 360;

  if (width > height) {
    // æ¨ªå‘è§†é¢‘
    if (width <= maxDim) {
      return { width, height };
    }
    const scale = maxDim / width;
    return {
      width: maxDim,
      height: Math.round(height * scale / 2) * 2, // ç¡®ä¿æ˜¯å¶æ•°
    };
  } else {
    // çºµå‘æˆ–æ­£æ–¹å½¢è§†é¢‘
    if (height <= maxDim) {
      return { width, height };
    }
    const scale = maxDim / height;
    return {
      width: Math.round(width * scale / 2) * 2, // ç¡®ä¿æ˜¯å¶æ•°
      height: maxDim,
    };
  }
}

/**
 * è½¬ç è§†é¢‘åˆ°360p
 */
async function transcodeToG360p(inputPath, outputPath) {
  console.log('å¼€å§‹è½¬ç :', inputPath, '->', outputPath);

  // 1. æ‰“å¼€è¾“å…¥æ–‡ä»¶
  const inputCtx = openInput(inputPath);
  const streams = getInputStreams(inputCtx);

  console.log('è¾“å…¥æµä¿¡æ¯:');
  streams.forEach((stream, idx) => {
    console.log(`  æµ #${idx}: ${stream.type}`, stream);
  });

  // 2. æ‰¾åˆ°è§†é¢‘å’ŒéŸ³é¢‘æµ
  const videoStreamIdx = streams.findIndex(s => s.type === 'video');
  const audioStreamIdx = streams.findIndex(s => s.type === 'audio');

  if (videoStreamIdx === -1) {
    throw new Error('æœªæ‰¾åˆ°è§†é¢‘æµ');
  }

  const videoStream = streams[videoStreamIdx];
  const audioStream = audioStreamIdx !== -1 ? streams[audioStreamIdx] : null;

  // 3. è®¡ç®—ç›®æ ‡åˆ†è¾¨ç‡
  const { width: targetWidth, height: targetHeight } = calculate360pSize(
    videoStream.width,
    videoStream.height
  );

  console.log(`\nç¼©æ”¾: ${videoStream.width}x${videoStream.height} -> ${targetWidth}x${targetHeight}`);

  // 4. åˆ›å»ºè§£ç å™¨
  const videoDecoder = createDecoder(videoStream.codec);
  copyDecoderParams(inputCtx, videoDecoder, videoStreamIdx);
  openDecoder(videoDecoder);

  let audioDecoder = null;
  if (audioStream) {
    audioDecoder = createDecoder(audioStream.codec);
    copyDecoderParams(inputCtx, audioDecoder, audioStreamIdx);
    openDecoder(audioDecoder);
  }

  // 5. åˆ›å»ºè¾“å‡ºæ–‡ä»¶
  const outputCtx = createOutput(outputPath, 'mp4');

  // **å…³é”®ï¼šè®¾ç½®faststarté€‰é¡¹ï¼ˆMOOVåŸå­å‰ç½®ï¼‰**
  setOutputOption(outputCtx, 'movflags', '+faststart');
  console.log('âœ“ å·²å¯ç”¨faststartï¼ˆMOOVå‰ç½®ï¼‰');

  // 6. åˆ›å»ºè§†é¢‘ç¼–ç å™¨ï¼ˆH.264ï¼‰
  const videoEncoder = createEncoder('libx264');

  // è®¾ç½®è§†é¢‘ç¼–ç å‚æ•°
  setEncoderOption(videoEncoder, 'width', targetWidth);
  setEncoderOption(videoEncoder, 'height', targetHeight);
  setEncoderOption(videoEncoder, 'pix_fmt', 'yuv420p'); // YUV420P
  setEncoderOption(videoEncoder, 'time_base_num', 1);
  setEncoderOption(videoEncoder, 'time_base_den', 30);
  setEncoderOption(videoEncoder, 'framerate_num', 30);
  setEncoderOption(videoEncoder, 'framerate_den', 1);

  // **ç ç‡æ§åˆ¶**
  setEncoderOption(videoEncoder, 'bit_rate', 800000); // 800 kbps
  setEncoderOption(videoEncoder, 'gop_size', 60); // 2ç§’GOP (30fps)
  setEncoderOption(videoEncoder, 'max_b_frames', 2);

  // H.264ç‰¹å®šé€‰é¡¹
  setEncoderOption(videoEncoder, 'preset', 'medium'); // ç¼–ç é€Ÿåº¦/è´¨é‡å¹³è¡¡
  setEncoderOption(videoEncoder, 'crf', '23'); // è´¨é‡æ§åˆ¶ (18-28èŒƒå›´)

  openEncoder(videoEncoder);
  console.log(`âœ“ è§†é¢‘ç¼–ç å™¨: H.264, ${targetWidth}x${targetHeight}, 800kbps, CRF=23`);

  // 7. æ·»åŠ è§†é¢‘æµ
  const outputVideoStreamIdx = addOutputStream(outputCtx, 'libx264');
  copyEncoderToStream(videoEncoder, outputCtx, outputVideoStreamIdx);

  // 8. åˆ›å»ºéŸ³é¢‘ç¼–ç å™¨ï¼ˆå¦‚æœæœ‰éŸ³é¢‘æµï¼‰
  let audioEncoder = null;
  let outputAudioStreamIdx = -1;

  if (audioStream) {
    audioEncoder = createEncoder('aac');

    setEncoderOption(audioEncoder, 'sample_rate', audioStream.sampleRate || 44100);
    setEncoderOption(audioEncoder, 'channels', audioStream.channels || 1);
    setEncoderOption(audioEncoder, 'sample_fmt', 'fltp'); // AACç¼–ç å™¨æ”¯æŒfltp
    setEncoderOption(audioEncoder, 'bit_rate', 128000); // 128 kbpséŸ³é¢‘ç ç‡
    setEncoderOption(audioEncoder, 'time_base_num', 1);
    setEncoderOption(audioEncoder, 'time_base_den', audioStream.sampleRate || 44100);

    openEncoder(audioEncoder);
    console.log(`âœ“ éŸ³é¢‘ç¼–ç å™¨: AAC, ${audioStream.sampleRate}Hz, ${audioStream.channels}ch, 128kbps`);

    outputAudioStreamIdx = addOutputStream(outputCtx, 'aac');
    copyEncoderToStream(audioEncoder, outputCtx, outputAudioStreamIdx);
  }

  // 9. åˆ›å»ºç¼©æ”¾ä¸Šä¸‹æ–‡
  const swsCtx = createSwsContext(
    videoStream.width,
    videoStream.height,
    videoStream.pixelFormat || 'yuv420p',
    targetWidth,
    targetHeight,
    'yuv420p'
  );
  console.log('âœ“ åˆ›å»ºè§†é¢‘ç¼©æ”¾ä¸Šä¸‹æ–‡');

  // 10. å†™å…¥æ–‡ä»¶å¤´
  writeHeader(outputCtx);
  console.log('âœ“ å†™å…¥æ–‡ä»¶å¤´ï¼ˆåŒ…å«faststarté€‰é¡¹ï¼‰\n');

  // 11. åˆ†é…å·¥ä½œå¸§å’ŒåŒ…
  const decodedVideoFrame = allocFrame();
  const scaledVideoFrame = allocFrame();
  const encodedVideoPacket = allocPacket();

  let decodedAudioFrame = null;
  let bufferedAudioFrame = null; // ç”¨äºå­˜æ”¾ç¼“å†²åŒºé‡ç»„åçš„éŸ³é¢‘å¸§
  let encodedAudioPacket = null;
  let audioBuffer = null; // éŸ³é¢‘å¸§ç¼“å†²å™¨

  if (audioStream) {
    decodedAudioFrame = allocFrame();
    bufferedAudioFrame = allocFrame();
    encodedAudioPacket = allocPacket();
    
    // âœ¨ åˆ›å»ºAudioFIFOéŸ³é¢‘å¸§ç¼“å†²å™¨ (AACéœ€è¦1024é‡‡æ ·/å¸§)
    // format=8 å¯¹åº” AV_SAMPLE_FMT_FLTP (planar float32)
    audioBuffer = new AudioFrameBuffer(1024, audioStream.channels, 8);
  }

  // è®¾ç½®ç¼©æ”¾åå¸§çš„å±æ€§
  setFrameProperty(scaledVideoFrame, 'width', targetWidth);
  setFrameProperty(scaledVideoFrame, 'height', targetHeight);
  setFrameProperty(scaledVideoFrame, 'format', 0); // YUV420P (AV_PIX_FMT_YUV420P = 0)
  frameGetBuffer(scaledVideoFrame, 32); // 32å­—èŠ‚å¯¹é½

  // 12. ä¸»è½¬ç å¾ªç¯
  let videoFrameCount = 0;
  let audioFrameCount = 0;
  let packetCount = 0;

  console.log('å¼€å§‹è½¬ç ...');

  while (true) {
    // è¯»å–è¾“å…¥åŒ…
    const packet = readPacket(inputCtx);
    if (!packet) {
      console.log('è¾“å…¥æ–‡ä»¶è¯»å–å®Œæ¯•ï¼Œåˆ·æ–°ç¼–ç å™¨...');

      // åˆ·æ–°è§†é¢‘ç¼–ç å™¨
      sendFrame(videoEncoder, null);
      while (true) {
        const ret = receivePacket(videoEncoder, encodedVideoPacket);
        if (ret !== 0) break;
        writePacket(outputCtx, encodedVideoPacket, outputVideoStreamIdx);
      }

      // åˆ·æ–°éŸ³é¢‘ç¼–ç å™¨
      if (audioEncoder) {
        // å…ˆå¤„ç†ç¼“å†²å™¨ä¸­å‰©ä½™çš„éŸ³é¢‘æ•°æ®
        while (audioBuffer.hasEnoughSamples()) {
          if (audioBuffer.extractFrame(bufferedAudioFrame)) {
            sendFrame(audioEncoder, bufferedAudioFrame);
            while (true) {
              const encRet = receivePacket(audioEncoder, encodedAudioPacket);
              if (encRet !== 0) break;
              writePacket(outputCtx, encodedAudioPacket, outputAudioStreamIdx);
              audioFrameCount++;
            }
          }
        }
        
        // åˆ·æ–°éŸ³é¢‘ç¼–ç å™¨ç¼“å†²åŒº
        sendFrame(audioEncoder, null);
        while (true) {
          const ret = receivePacket(audioEncoder, encodedAudioPacket);
          if (ret !== 0) break;
          writePacket(outputCtx, encodedAudioPacket, outputAudioStreamIdx);
        }
        
        console.log(`éŸ³é¢‘ç¼“å†²å™¨å‰©ä½™: ${audioBuffer.totalSamples} é‡‡æ ·æœªå¤„ç†`);
      }

      break;
    }

    packetCount++;
    const streamIdx = getPacketProperty(packet.id, 'streamIndex');

    if (streamIdx === videoStreamIdx) {
      // å¤„ç†è§†é¢‘åŒ…
      sendPacket(videoDecoder, packet.id);

      while (true) {
        const ret = receiveFrame(videoDecoder, decodedVideoFrame);
        if (ret !== 0) break;

        // ç¼©æ”¾å¸§
        swsScale(swsCtx, decodedVideoFrame, scaledVideoFrame);

        // ç¼–ç ç¼©æ”¾åçš„å¸§
        sendFrame(videoEncoder, scaledVideoFrame);

        // æ¥æ”¶ç¼–ç åŒ…
        while (true) {
          const encRet = receivePacket(videoEncoder, encodedVideoPacket);
          if (encRet !== 0) break;

          writePacket(outputCtx, encodedVideoPacket, outputVideoStreamIdx);
          videoFrameCount++;
        }
      }

    } else if (audioStream && streamIdx === audioStreamIdx) {
      // å¤„ç†éŸ³é¢‘åŒ…
      sendPacket(audioDecoder, packet.id);

      while (true) {
        const ret = receiveFrame(audioDecoder, decodedAudioFrame);
        if (ret !== 0) break;

        // è·å–éŸ³é¢‘å¸§çš„é‡‡æ ·æ•°
        const nbSamples = getFrameProperty(decodedAudioFrame, 'nb_samples');
        
        // âœ¨ ä½¿ç”¨AudioFIFOç¼“å†²é‡ç»„
        // å°†è§£ç åçš„éŸ³é¢‘å¸§æ·»åŠ åˆ°FIFOç¼“å†²åŒº
        audioBuffer.addFrame(decodedAudioFrame);
        
        // å°è¯•ä»ç¼“å†²åŒºæå–å®Œæ•´çš„1024é‡‡æ ·å¸§å¹¶ç¼–ç 
        while (audioBuffer.hasEnoughSamples()) {
          if (audioBuffer.extractFrame(bufferedAudioFrame)) {
            // ç¼–ç ç¼“å†²åçš„éŸ³é¢‘å¸§
            sendFrame(audioEncoder, bufferedAudioFrame);

            while (true) {
              const encRet = receivePacket(audioEncoder, encodedAudioPacket);
              if (encRet !== 0) break;

              writePacket(outputCtx, encodedAudioPacket, outputAudioStreamIdx);
              audioFrameCount++;
            }
          }
        }
      }
    }

    freePacket(packet.id);

    // è¿›åº¦æ˜¾ç¤º
    if (packetCount % 100 === 0) {
      process.stdout.write(`\rå¤„ç†åŒ…: ${packetCount}, è§†é¢‘å¸§: ${videoFrameCount}, éŸ³é¢‘å¸§: ${audioFrameCount}`);
    }
  }

  console.log(`\n\nè½¬ç å®Œæˆ:`);
  console.log(`  - å¤„ç†åŒ…æ•°: ${packetCount}`);
  console.log(`  - è§†é¢‘å¸§æ•°: ${videoFrameCount}`);
  console.log(`  - éŸ³é¢‘å¸§æ•°: ${audioFrameCount}`);

  // 13. å†™å…¥æ–‡ä»¶å°¾å¹¶æ¸…ç†
  writeTrailer(outputCtx);

  freeFrame(decodedVideoFrame);
  freeFrame(scaledVideoFrame);
  freePacket(encodedVideoPacket);

  if (audioStream) {
    freeFrame(decodedAudioFrame);
    freeFrame(bufferedAudioFrame);
    freePacket(encodedAudioPacket);
    audioBuffer.destroy(); // âœ¨ é‡Šæ”¾AudioFIFOèµ„æº
  }

  closeContext(videoDecoder);
  closeContext(videoEncoder);
  closeContext(swsCtx);

  if (audioDecoder) closeContext(audioDecoder);
  if (audioEncoder) closeContext(audioEncoder);

  closeContext(inputCtx);
  closeContext(outputCtx);

  console.log('\nâœ“ æ‰€æœ‰èµ„æºå·²æ¸…ç†');
  console.log(`âœ“ è¾“å‡ºæ–‡ä»¶: ${outputPath}`);
  console.log('âœ“ MOOVåŸå­å·²å‰ç½®ï¼ˆfaststartï¼‰ï¼Œå¯ç›´æ¥æµå¼æ’­æ”¾');
  console.log('\nğŸ“Š æ–°ç‰¹æ€§ä½¿ç”¨è¯´æ˜ï¼š');
  console.log('  âœ¨ AudioFIFO: ä½¿ç”¨FFmpegåŸç”ŸAPIè¿›è¡ŒéŸ³é¢‘ç¼“å†²é‡ç»„');
  console.log('  âœ¨ Channelså±æ€§: æ”¯æŒæ‰‹åŠ¨è®¾ç½®éŸ³é¢‘å¸§å£°é“æ•°');
  console.log('  âœ¨ é›¶æ‹·è´: Frameæ•°æ®ç›´æ¥åœ¨Cå±‚ä¼ è¾“ï¼Œæ— JSå¼€é”€');
}

// è¿è¡Œç¤ºä¾‹
const inputFile = path.join(__dirname, 'input.mp4');
const outputFile = path.join(__dirname, 'output/360p-output.mp4');

transcodeToG360p(inputFile, outputFile)
  .then(() => {
    console.log('\næˆåŠŸï¼');
    process.exit(0);
  })
  .catch((error) => {
    console.error('\né”™è¯¯:', error);
    process.exit(1);
  });

